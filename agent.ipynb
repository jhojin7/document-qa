{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.12'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install -U langchain-ollama\n",
    "# %pip install -U ollama\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/chat/ollama/\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/faiss_async/\n",
    "# https://python.langchain.com/docs/how_to/migrate_agent/#in-langgraph-2\n",
    "\n",
    "import langchain\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 유저 입력 ===\n",
      "폰 새로 사야하는데 추천좀.\n",
      "=== 챗봇 출력 ===\n",
      "<doc># Docuent 3:\n",
      "I love the new iPhone. It has a great camera and the battery life is amazing.</doc>\n",
      "=== 유저 입력 ===\n",
      "폰 새로 사야하는데 추천좀.\n",
      "=== 챗봇 출력 ===\n",
      "It sounds like you're looking to buy a new phone!\n",
      "\n",
      "You might want to consider getting an iPhone, based on what I've read about them. They seem to have some really great features, such as a fantastic camera and impressive battery life.\n",
      "\n",
      "Would you like me to suggest more options or provide more information about iPhones?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "docs = [\n",
    "    \"This restaurant is great. The food is delicious and the service is excellent.\",\n",
    "    \"AIMessage is a great tool for building chatbots.\",\n",
    "    \"I love the new iPhone. It has a great camera and the battery life is amazing.\",\n",
    "    \"Hello, how are you?\",\n",
    "    \"I am doing well. Thank you for asking.\",\n",
    "]\n",
    "docs_str = \"\"\n",
    "for doc in docs:\n",
    "    docs_str += f\"<doc># Docuent {docs.index(doc) + 1}:\\n\"\n",
    "    docs_str += f\"{doc}</doc>\\n\"\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0, verbose=True)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     name=\"Document Curation Chatbot\",\n",
    "#     input_variables=[\"query\", \"docs\"],\n",
    "#     template=\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 여러개의 문서를 가지고 분석하여 사용자에게 큐레이션을 할 수 있는 챗봇입니다.\n",
    "아래의 문서들을 분석하여 사용자의 입력에 제일 적합한 내용 하나만을 선택해 제공해주세요.\n",
    "다음 세 가지 기준을 고려하여 선택해주세요.\n",
    "1. Direct relevance of the document to the user's input\n",
    "2. The quality of the document in terms of informativeness and readability\n",
    "3. The diversity of the documents selected\n",
    "각 문서는 `<doc>`와 `</doc>`로 감싸져 있습니다.\n",
    "사용자의 입력은 `<user>`와 `</user>`로 감싸져 있습니다. 사용자의 입력은 항상 마지막에 위치합니다.\n",
    "당신의 답변은 선택된 문서를 `<doc>`와 `</doc>`로 감싸져 있어야 합니다. 다른 내용은 없어야 합니다.\n",
    "---\n",
    "\n",
    "<user>{query}</user>\n",
    "{docs}\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "user_query = \"폰 새로 사야하는데 추천좀.\"\n",
    "output = chain.invoke({\"query\": user_query, \"docs\": docs_str})\n",
    "\n",
    "print(\"=== 유저 입력 ===\")\n",
    "print(user_query)\n",
    "print(\"=== 챗봇 출력 ===\")\n",
    "print(output.content)\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(\n",
    "    \"\"\"You are given user's input and a list of curated documents for the user.\n",
    "Analyze the input and the documents and answer the user in a positive and helpful manner.\n",
    "The user's input is wrapped in <user> and </user> tags. The user's input is always at the end.\n",
    "The curated documents are wrapped in <doc> and </doc> tags.\n",
    "---\n",
    "<user>{query}</user>\n",
    "{docs}\n",
    "\"\"\"\n",
    ")\n",
    "chain2 = prompt2 | llm\n",
    "output2 = chain2.invoke({\"query\": user_query, \"docs\": output.content})\n",
    "\n",
    "print(\"=== 유저 입력 ===\")\n",
    "print(user_query)\n",
    "print(\"=== 챗봇 출력 ===\")\n",
    "print(output2.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
